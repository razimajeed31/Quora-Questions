{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['embeddings', 'train.csv', 'sample_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45bcf9edc667abd4797d0475ca45d854e8ed26b6"
      },
      "cell_type": "code",
      "source": "import time\nfrom tqdm import tqdm\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, CuDNNLSTM\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1696d674b6b077e1ac80493d4e5fac779e77753"
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e78dca0b94a0750d0534c3fe6a82f1ea1f714857"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom keras.preprocessing.sequence import pad_sequences",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "137b67f0aa2a387ee3057df6a031d7a58f3217bb"
      },
      "cell_type": "code",
      "source": "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0ce7b6ab36c1873d565de63ab1f302e23f693b2"
      },
      "cell_type": "code",
      "source": "#embed_size = 300 # how big is each word vector\nmax_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 200 # max number of words in a question to use\ntrain_X = train_df[\"question_text\"].fillna(\"_na_\").values\nval_X = val_df[\"question_text\"].fillna(\"_na_\").values\ntest_X = test_df[\"question_text\"].fillna(\"_na_\").values",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31309996adff263cf2918e9629a70514bc7ae020"
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(train_X))\ntrain_X = tokenizer.texts_to_sequences(train_X)\nval_X = tokenizer.texts_to_sequences(val_X)\ntest_X = tokenizer.texts_to_sequences(test_X)\n\n## Pad the sentences \ntrain_X = pad_sequences(train_X, maxlen=maxlen)\nval_X = pad_sequences(val_X, maxlen=maxlen)\ntest_X = pad_sequences(test_X, maxlen=maxlen)\n\n## Get the target values\ntrain_y = train_df['target'].values\nval_y = val_df['target'].values",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c801859596c3822fbe5f6fa1e5717540ecbbdd2"
      },
      "cell_type": "code",
      "source": "#np.random.seed(2018)\n#trn_idx = np.random.permutation(len(train_X))\n#val_idx = np.random.permutation(len(val_X))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dacb86f33fe448f0e4c14f958e0a29be0d0bbd46"
      },
      "cell_type": "code",
      "source": "#train_X = train_X[trn_idx]\n#val_X = val_X[val_idx]\n#train_y = train_y[trn_idx]\n#val_y = val_y[val_idx]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3475695932a0526d66f373651eee3a0ac62bef11"
      },
      "cell_type": "code",
      "source": "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c119586d3b6041d47ad11ed1666f40d2b3e5f46f"
      },
      "cell_type": "code",
      "source": "all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nembed_size = all_embs.shape[1]",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2a320b4e9347b626cd605928b547699f1a1e350"
      },
      "cell_type": "code",
      "source": "word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4d6dc59d50c1c81d9f69937ac6c75bc0e700626"
      },
      "cell_type": "code",
      "source": "inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n#x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aadce9cf9a283ee9464d04c45d289a37a1b0b26d"
      },
      "cell_type": "code",
      "source": "model.fit(train_X, train_y, batch_size=512, epochs=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b532e55559d0203750beaa8f66e51458ef9bba3"
      },
      "cell_type": "code",
      "source": "#pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "835f816f77e1b97fa0f5cdf1f16188b65272e4c6"
      },
      "cell_type": "code",
      "source": "#for thresh in np.arange(0.1, 0.501, 0.01):\n #   thresh = np.round(thresh, 2)\n  #  print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5e7f712e241d5013394a50b3671da3b838f8a68"
      },
      "cell_type": "code",
      "source": "pred_GRU = model.predict([test_X], batch_size=1024, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce4406a9c28afa065a5d85e1f8b727a1195d2131"
      },
      "cell_type": "markdown",
      "source": "del model, inp, x\nimport gc; gc.collect()\ntime.sleep(10)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48a3477da2851ccd6124e466373ba04808eb49af"
      },
      "cell_type": "markdown",
      "source": "inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n#x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3452cf5b22ed6c484797632fab5d752eeac57051"
      },
      "cell_type": "markdown",
      "source": "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "634e432836e1ff83b680669d7c82012741631540"
      },
      "cell_type": "markdown",
      "source": "pred_LSTM = model.predict([test_X], batch_size=1024, verbose=1)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ef24a1cf82cc3ee622568b12eaedc4fd9d527a3"
      },
      "cell_type": "markdown",
      "source": "pred_LSTM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40ab843c2c827b4e93949fd6d43721f5061e64df"
      },
      "cell_type": "markdown",
      "source": "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\nimport gc; gc.collect()\ntime.sleep(10)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f51f96a338dc3225cc9ed9e287af71f2a1126200"
      },
      "cell_type": "markdown",
      "source": "EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "730c913fa21b0c789e57b527fd70db573081b304"
      },
      "cell_type": "markdown",
      "source": "all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nembed_size = all_embs.shape[1]"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b89cc818fc5de0405a086deeb682c0133a55e82f"
      },
      "cell_type": "markdown",
      "source": "word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14f22acf9c1ca5a0b2637f0d205c82a4382a4b72"
      },
      "cell_type": "markdown",
      "source": "inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n#x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75be23cb7326bd71bf4b40b5d37c6888cb03c9f6"
      },
      "cell_type": "markdown",
      "source": "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b435d681c4a0ab7dd6f9c5eff0446d2e1aa4d19"
      },
      "cell_type": "markdown",
      "source": "pred_LSTMtwo = model.predict([test_X], batch_size=1024, verbose=1)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f595859c450bd8af8543618ce4f01479a1dad09"
      },
      "cell_type": "markdown",
      "source": "pred_GRU = (pred_GRU>0.5).astype(int)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e62820031a7e4e68fdeb88d5dc5d23772c8622d"
      },
      "cell_type": "markdown",
      "source": "pred_LSTM = (pred_LSTM>0.5).astype(int)\npred_LSTMtwo = (pred_LSTMtwo>0.5).astype(int)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7809ea731a49d7ee78a81ec633049040a3dae4a"
      },
      "cell_type": "markdown",
      "source": "type(pred_GRU)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aefc676adbb02bfb19d5fee915b78e4688d94cf8"
      },
      "cell_type": "code",
      "source": "#pred = 0.33*pred_glove_test_y + 0.33*pred_fasttext_test_y + 0.34*pred_paragram_test_y\n#pred = 0.34*pred_LSTM + 0.33*pred_GRU+0.33*pred_LSTMtwo\npred_test_y = (pred_GRU>0.29).astype(int)\nout_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\nout_df['prediction'] = pred_test_y\nout_df.to_csv(\"submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}